{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shelter Animal Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando más algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retomaremos el método usado en el ejemplo del Titanic, pero ahora para otro caso: el destino de los animales en un albergue. A diferencia del caso del Titanic donde solo había 2 posibles finales para cada pasajero (sobrevivió o no sobrevivió), cada animal puede resultar adoptado, transferido, regresado a su dueño, sacrificado o muerto.\n",
    "\n",
    "Al ver que varios códigos de otros usuarios se concentraban más en analizar los datos que pasarlos por un algoritmo, decidí comenzar usando el mismo método que en el Titanic, pero al final probé con otros algoritmos para hacer comparaciones.\n",
    "\n",
    "El Leaderboard de este ejemplo en Kaggle\n",
    "https://www.kaggle.com/c/shelter-animal-outcomes/leaderboard\n",
    "\n",
    "El usuario con el que probé mis resultados es *a-s-ulloa92*\n",
    "\n",
    "Comenzamos importando las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier                         # KNN\n",
    "from sklearn.svm import SVC                                                # SVM\n",
    "from sklearn.ensemble import RandomForestClassifier                        # Bósque aleatorios\n",
    "from sklearn.ensemble import AdaBoostClassifier                            # ADA Boost\n",
    "from sklearn.naive_bayes import GaussianNB                                 # Naive bayes\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis       # Logística sin regularización\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis    # Logística con polinomio de orden 2\n",
    "from sklearn.linear_model import  LogisticRegression                       # Logística con regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos los datos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consiguiendo los datos de entrenamiento y el conjunto de prueba...\n",
      "Datos de entrenamiento: 26729\n",
      "Datos de prueba: 11456\n"
     ]
    }
   ],
   "source": [
    "print('Consiguiendo los datos de entrenamiento y el conjunto de prueba...')\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print 'Datos de entrenamiento:', len(train)\n",
    "\n",
    "print 'Datos de prueba:', len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos algunas funciones sencillas para pasar a enteros o flotantes los atributos de los animales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def texto_a_edad(age):\n",
    "    \"\"\"\n",
    "    Consigue la edad de un string y regresa un float. El tiempo es en meses y se considera que un mes son 4 semanas\n",
    "    \"\"\"\n",
    "    if pd.isnull(age):\n",
    "        return age\n",
    "    \n",
    "    if 'year' in age:\n",
    "        return 12*int(re.search(r'\\d+', age).group())\n",
    "    \n",
    "    if 'month' in age:\n",
    "        return int(re.search(r'\\d+', age).group())\n",
    "    \n",
    "    if 'week' in age:\n",
    "        return 0.25*int(re.search(r'\\d+', age).group())\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def esCruza(breed):\n",
    "    \"\"\"\n",
    "    Regresa 1 si el perro es una cruza (no de raza pura); 0 en otro caso\n",
    "    \"\"\"\n",
    "\n",
    "    if 'Mix' in breed:\n",
    "        return 1\n",
    "    \n",
    "    if '/' in breed:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def perro_o_gato(x):\n",
    "    \"\"\"\n",
    "    Si el animal es un perro, regresa 1; si es un gato, regresa 0\n",
    "    \"\"\"\n",
    "    if 'Dog' in x: return 1\n",
    "    else: return 0\n",
    "\n",
    "def get_sex(x):\n",
    "    \"\"\"\n",
    "    Si el animal es macho, regresa 2; si es hembra, regresa 1; si no se conoce su sexo, regresa 0\n",
    "    \"\"\"\n",
    "    if x.find('Male') >= 0: return 2\n",
    "    if x.find('Female') >= 0: return 1\n",
    "    return 0\n",
    "\n",
    "def get_neutered(x):\n",
    "    \"\"\"\n",
    "    Si el animal está esterilizado, regresa 2; si no lo está, regresa 1; si se desconoce, se regresa 0\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    if x.find('Spayed') >= 0: return 2\n",
    "    if x.find('Neutered') >= 0: return 2\n",
    "    if x.find('Intact') >= 0: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con ayuda de estas funciones, declararemos otra para usarlas y además eliminar campos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_data(animals):\n",
    "    # Llena campos vacíos\n",
    "    animals[\"Name\"] = animals[\"Name\"].fillna(0)\n",
    "    animals[\"SexuponOutcome\"] = animals[\"SexuponOutcome\"].fillna('Unknown')\n",
    "    \n",
    "    \n",
    "    #Pasa a enteros la edad\n",
    "    animals['Age'] = animals.AgeuponOutcome.apply(texto_a_edad)\n",
    "    \n",
    "    #Determina si el animal es cruza o no\n",
    "    animals['Breed'] = animals.Breed.apply(esCruza)\n",
    "    \n",
    "    #Asigna un entero dependiendo del sexo del animal\n",
    "    animals['Sex'] = animals.SexuponOutcome.apply(get_sex)\n",
    "    \n",
    "    #Asigna un entero dependiendo de si el animal está o no esterilizado\n",
    "    animals['Neutered'] = animals.SexuponOutcome.apply(get_neutered)\n",
    "    \n",
    "    #Asigna un valor dependiendo de si el animal es perro o gato\n",
    "    animals['Type'] = animals.AnimalType.apply(perro_o_gato)\n",
    "    \n",
    "    #Elimina campos en blanco de la columna Age\n",
    "    animals[\"Age\"] = animals[\"Age\"].fillna(animals[\"Age\"].mean())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Asigna valores numéricos a los datos para facilitar cálculos\n",
    "    animals.loc[animals[\"Name\"] != 0, \"Name\"] = 1\n",
    "    \n",
    "    return animals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sigue usar esta función para \"arreglar\" tanto los datos de entrenamiento como los de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = fix_data(train)\n",
    "test_data  = fix_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos la función que usaremos más adelante para guardar nuestrar predicciones. Comenzamos con la columna de ID y las siguientes corresponden a cada posible estado en el que puede terminar cada animal. En cada fila estas columnas tendrán el valor de 0 con excepción de una, dependiendo del estado final correspondiente de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_submission(dtc, train, test, predictors, filename):\n",
    "    dtc.fit(train[predictors], train[\"OutcomeType\"])\n",
    "    predictions = dtc.predict(test[predictors])\n",
    "    \n",
    "    temp = pd.DataFrame({\n",
    "        \"ID\": test[\"ID\"],\n",
    "        \"Type\": predictions,\n",
    "        \"Return_to_owner\":0,\n",
    "        \"Euthanasia\":0,\n",
    "        \"Transfer\":0,\n",
    "        \"Died\":0,\n",
    "        \"Adoption\":0\n",
    "    })\n",
    "    \n",
    "    temp.loc[temp[\"Type\"] == \"Return_to_owner\", \"Return_to_owner\"] = 1\n",
    "    temp.loc[temp[\"Type\"] == \"Euthanasia\", \"Euthanasia\"] = 1\n",
    "    temp.loc[temp[\"Type\"] == \"Transfer\", \"Transfer\"] = 1\n",
    "    temp.loc[temp[\"Type\"] == \"Died\", \"Died\"] = 1\n",
    "    temp.loc[temp[\"Type\"] == \"Adoption\", \"Adoption\"] = 1\n",
    "\n",
    "    temp = temp.drop('Type', 1)\n",
    "\n",
    "    temp.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardaremos en una lista los datos que usaremos para nuestras predicciones. Estos campos son:\n",
    "* Nombre\n",
    "* Raza\n",
    "* Sexo\n",
    "* Edad\n",
    "* Esterilizado\n",
    "* Tipo (Si es perro o gato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Name\", \"Breed\", \"Sex\", \"Age\", \"Neutered\", \"Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En *sklearn* los árboles incluyen la función *score*, la cual regresa la precisión de los datos de prueba, dando como parámetros estos datos y las clases a las que pertenece cada uno. Usaremos esto para calcular la profundidad (llamada *max_depth* por el algoritmo) que nos dé los resultados más acertados, probando cada caso del 1 al 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0.64690055915105815)\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "best_n = 0\n",
    "for n in range(1,100):\n",
    "    dtc_scr = 0.\n",
    "    dtc = DecisionTreeClassifier(max_depth=n)\n",
    "    for train, test in KFold(len(train_data), n_folds=10, shuffle=True):\n",
    "        dtc.fit(train_data[predictors].T[train].T, train_data[\"OutcomeType\"].T[train].T)\n",
    "        dtc_scr += dtc.score(train_data[predictors].T[test].T, train_data[\"OutcomeType\"].T[test].T)/10\n",
    "    if dtc_scr > max_score:\n",
    "        max_score = dtc_scr\n",
    "        best_n = n\n",
    "print(best_n, max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro parámetro del arbol de decisión es *min_samples_split*, el cual es el mínimo número de muestras necesarias para partir un nodo. Al igual que con la profundidad, buscaremos el mejor valor para nuestro algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 0.64581578985687449)\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "best_s = 0\n",
    "for s in range(1,100):\n",
    "    dtc_scr = 0.\n",
    "    dtc = DecisionTreeClassifier(min_samples_split=s)\n",
    "    for train, test in KFold(len(train_data), n_folds=10, shuffle=True):\n",
    "        dtc.fit(train_data[predictors].T[train].T, train_data[\"OutcomeType\"].T[train].T)\n",
    "        dtc_scr += dtc.score(train_data[predictors].T[test].T, train_data[\"OutcomeType\"].T[test].T)/10\n",
    "    if dtc_scr > max_score:\n",
    "        max_score = dtc_scr\n",
    "        best_s = s\n",
    "print(best_s, max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de esto ya podemos crear nuestro arbol de decisión. El código original usaba como criterio *entropy* y un separador de nodos *random*. El criterio puede cambiarse a *gini* para usar la impureza de Gini en vez de ganancia de información, y como estrategia para el separador se puede cambiar a *best* para elegir la mejor separación (*random* usa la mejor separación aleatoria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = DecisionTreeClassifier(max_depth=best_n, min_samples_split=best_s, criterion='entropy', splitter='random')\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"sheltersurvivors.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasa si usamos otro algoritmo? Ahora probaremos con un Naive-Bayes gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = GaussianNB()\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"sheltersurvivors-NB.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado fue un poco peor que el primero, pero ayuda a darnos cuenta que el algoritmo que usemos es importante y afectará nuestros resultados.\n",
    "\n",
    "Haremos unas últimas pruebas con regresión logística. Primero, con los valores por default del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = LogisticRegression()\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"sheltersurvivors-log1.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora con una regularización un poco más estricta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = LogisticRegression(C = 0.5)\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"sheltersurvivors-log2.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un último intento, pero con menos regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haciendo predicciones...\n",
      "Creando archivo Excel...\n",
      "Listo.\n"
     ]
    }
   ],
   "source": [
    "print('Haciendo predicciones...')\n",
    "dtc = LogisticRegression(C = 2)\n",
    "print('Creando archivo Excel...')\n",
    "create_submission(dtc, train_data, test_data, predictors, \"sheltersurvivors-log3.csv\")\n",
    "print('Listo.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenando los algoritmos por el resultado obtenido, de mejor a peor, tendríamos:\n",
    "* Árboles de decisión\n",
    "* Regresión logística (regularización alta)\n",
    "* Regresión logística (regularización normal o baja)\n",
    "* Naive-Bayes Gaussiano"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
